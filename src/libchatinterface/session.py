"""Session management for chat interface with complete message history tracking."""

import contextlib
import json
import os
import re
from datetime import UTC, datetime
from pathlib import Path
from typing import Any

import tiktoken
from pydantic_ai.messages import ModelMessage, ModelRequest, ModelResponse
from pydantic_ai.usage import RunUsage
from pydantic_core import to_jsonable_python

from libchatinterface.costs import (
    SessionCosts,
    add_usage_to_session,
    calculate_usage_cost,
    format_session_costs_for_metadata,
)


class SessionManager:
    """Manages chat sessions with complete message history and metadata tracking."""

    def __init__(self, app_name: str = "chatinterface", context_window: int | None = None):
        """Initialize session manager with a new session.

        Args:
            app_name: Application name for directory structure (default: "chatinterface")
            context_window: Maximum context window size in tokens (default: from CONTEXT_WINDOW env var or 200,000)
        """
        # Read context window from environment variable if not provided
        if context_window is None:
            context_window = int(os.getenv("CONTEXT_WINDOW", "200000"))
        self.app_name = app_name
        self.sessions_dir = Path.home() / f".{app_name}" / "sessions"
        self.session_timestamp = datetime.now(UTC).isoformat().replace(":", "_")
        self.session_dir = self.sessions_dir / self.session_timestamp
        self.metadata_file = self.session_dir / "metadata.json"
        self.history_file = self.session_dir / "history.jsonl"

        # Session tracking
        self.first_user_message: str | None = None
        self.message_count = 0
        self.last_message_timestamp: str | None = None
        self.messages: list[dict[str, Any]] = []

        # Title caching - only generate once
        self._session_title: str | None = None
        self._title_generated = False

        # Cost tracking
        self.session_costs = SessionCosts()

        # Context compression
        self.context_window = context_window
        self.compressed_context: str | None = None
        self._encoding = tiktoken.encoding_for_model("gpt-4")  # Token estimation

        # Create session directory
        self._create_session_directory()

    def _create_session_directory(self) -> None:
        """Create the session directory structure."""
        try:
            self.session_dir.mkdir(parents=True, exist_ok=True)
        except Exception as e:
            # If we can't create the directory, we'll fail silently and continue
            # This prevents the chat from breaking if there are permission issues
            print(f"Warning: Could not create session directory: {e}")

    async def _extract_title(self, message: str) -> str:
        """Extract a meaningful title from the first user message using AI inference.

        Args:
            message: The first user message

        Returns:
            A concise, meaningful title (≤5 words) generated by the title agent
        """
        try:
            # Import here to avoid circular imports
            from libagentic.agents import get_title_agent

            # Create the title generation agent using the established pattern
            title_agent = get_title_agent()

            # Generate title using the agent
            result = await title_agent.run(f"Generate a title for this message: {message}")
            generated_title = result.output.strip()

            # Track usage from title generation
            try:
                title_usage = result.usage()
                title_model = getattr(result, "model_name", None)
                if title_usage:
                    self.log_run_usage(title_usage, title_model)
            except Exception:
                # If we can't get usage data, continue without tracking
                pass

            # Remove quotes if present
            if generated_title.startswith('"') and generated_title.endswith('"'):
                generated_title = generated_title[1:-1].strip()

            # Validate the generated title
            if generated_title and len(generated_title.split()) <= 5:
                return generated_title
            else:
                # Fallback to first 5 words if AI response is invalid
                return " ".join(message.split()[:5])

        except Exception as e:
            # Print error for debugging but continue with fallback
            print(f"AI title generation failed: {e}")
            # Fallback to simple extraction if AI generation fails
            return self._extract_title_fallback(message)

    def _extract_title_fallback(self, message: str) -> str:
        """Fallback title extraction using simple word processing.

        Args:
            message: The user message

        Returns:
            A title with first 5 meaningful words
        """
        # Clean the message and take first 5 words
        clean_message = re.sub(r"[^\w\s]", " ", message)
        words = [word for word in clean_message.split() if word.strip()]

        # Take first 5 words with proper capitalization
        title_words = words[:5]
        if title_words:
            # Capitalize first word, preserve original case for others (like "Python")
            title_words[0] = title_words[0].capitalize()
            title = " ".join(title_words)
            return title

        return "New Chat"

    def _log_message_to_history(self, message_data: dict[str, Any]) -> None:
        """Log a message to the history.jsonl file.

        Args:
            message_data: Message data to log
        """
        try:
            with self.history_file.open("a", encoding="utf-8") as f:
                json_line = json.dumps(message_data, ensure_ascii=False)
                f.write(json_line + "\n")
        except Exception:
            # Silently fail if we can't write to the file
            pass

    def _update_metadata(self, title: str | None = None) -> None:
        """Update the metadata.json file with current session information.

        Args:
            title: Optional pre-generated title to use (only used once)
        """
        with contextlib.suppress(Exception):
            # Set title only once - prioritize provided title
            if title and not self._title_generated:
                self._session_title = title
                self._title_generated = True
            # Don't eagerly generate fallback title - let AI title generation handle this

            # Use current title or placeholder
            current_title = self._session_title or "New Chat"

            metadata = {
                "title": current_title,
                "created_timestamp": self.session_timestamp.replace("_", ":"),  # Convert back to proper ISO format
                "message_count": self.message_count,
                "last_message_timestamp": self.last_message_timestamp,
                "usage": format_session_costs_for_metadata(self.session_costs),
            }

            with self.metadata_file.open("w", encoding="utf-8") as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)

    async def update_title_with_ai(self) -> None:
        """Update the session title using AI inference after first user message."""
        if not self.first_user_message or self._title_generated:
            return

        try:
            # Generate AI title only if not already generated
            ai_title = await self._extract_title(self.first_user_message)
            # Update metadata with the AI-generated title (this will set _title_generated=True)
            self._update_metadata(title=ai_title)
        except Exception:
            # If AI title generation fails completely, use fallback
            fallback_title = self._extract_title_fallback(self.first_user_message)
            self._update_metadata(title=fallback_title)

    def log_run_usage(self, usage: RunUsage, model_name: str | None = None) -> None:
        """Log token usage and costs from a Pydantic AI run.

        Args:
            usage: RunUsage object from Pydantic AI result
            model_name: Name of the model used (for cost calculation)
        """
        # Calculate costs for this usage
        usage_costs = calculate_usage_cost(usage, model_name)

        # Add to session totals
        add_usage_to_session(self.session_costs, usage_costs)

        # Update metadata to reflect new costs
        self._update_metadata()

    def log_system_prompt(self, system_prompt: str) -> None:
        """Log the system prompt as the first message in the session.

        Args:
            system_prompt: The system prompt content
        """
        timestamp = datetime.now(UTC).isoformat()

        message_data = {
            "timestamp": timestamp,
            "type": "system_prompt",
            "content": system_prompt,
            "message_index": self.message_count,
        }

        self.messages.append(message_data)
        self.message_count += 1
        self.last_message_timestamp = timestamp

        self._log_message_to_history(message_data)
        self._update_metadata()

    def log_user_message(self, message: str) -> None:
        """Log a user message to the session.

        Args:
            message: The user message content
        """
        timestamp = datetime.now(UTC).isoformat()

        # Capture first user message for title generation
        if self.first_user_message is None:
            self.first_user_message = message

        message_data = {
            "timestamp": timestamp,
            "type": "user_message",
            "content": message,
            "message_index": self.message_count,
        }

        self.messages.append(message_data)
        self.message_count += 1
        self.last_message_timestamp = timestamp

        self._log_message_to_history(message_data)
        self._update_metadata()  # Will use fallback title for now

    def log_assistant_response(self, response: str) -> None:
        """Log an assistant response to the session.

        Args:
            response: The assistant response content
        """
        timestamp = datetime.now(UTC).isoformat()

        message_data = {
            "timestamp": timestamp,
            "type": "assistant_response",
            "content": response,
            "message_index": self.message_count,
        }

        self.messages.append(message_data)
        self.message_count += 1
        self.last_message_timestamp = timestamp

        self._log_message_to_history(message_data)
        self._update_metadata()

    def log_pydantic_messages(self, pydantic_messages: list[ModelMessage]) -> None:
        """Log Pydantic AI ModelMessage objects to the session.

        This method extracts and logs all message types from Pydantic AI's message system,
        including system prompts, user messages, and assistant responses.

        Args:
            pydantic_messages: List of Pydantic AI ModelMessage objects
        """
        for msg in pydantic_messages:
            timestamp = datetime.now(UTC).isoformat()

            if isinstance(msg, ModelRequest):
                # Process each part in the request
                for part in msg.parts:
                    if hasattr(part, "content"):
                        # Determine message type based on part type
                        if part.__class__.__name__ == "SystemPromptPart":
                            msg_type = "system_prompt"
                        elif part.__class__.__name__ == "UserPromptPart":
                            msg_type = "user_message"
                            # Capture first user message for title
                            if self.first_user_message is None and hasattr(part, "content"):
                                self.first_user_message = part.content
                        else:
                            msg_type = "request_part"

                        message_data = {
                            "timestamp": timestamp,
                            "type": msg_type,
                            "content": part.content,
                            "message_index": self.message_count,
                            "pydantic_type": part.__class__.__name__,
                            "pydantic_data": to_jsonable_python(part),
                        }

                        self.messages.append(message_data)
                        self.message_count += 1
                        self.last_message_timestamp = timestamp

                        self._log_message_to_history(message_data)

            elif isinstance(msg, ModelResponse):
                # Process each part in the response
                for part in msg.parts:
                    if hasattr(part, "content"):
                        message_data = {
                            "timestamp": timestamp,
                            "type": "assistant_response",
                            "content": part.content,
                            "message_index": self.message_count,
                            "pydantic_type": part.__class__.__name__,
                            "pydantic_data": to_jsonable_python(part),
                            "model_name": getattr(msg, "model_name", None),
                            "usage": to_jsonable_python(getattr(msg, "usage", None)) if hasattr(msg, "usage") else None,
                        }

                        self.messages.append(message_data)
                        self.message_count += 1
                        self.last_message_timestamp = timestamp

                        self._log_message_to_history(message_data)

        # Update metadata after processing all messages
        self._update_metadata()

    def get_session_info(self) -> dict[str, Any]:
        """Get current session information.

        Returns:
            Dictionary with session metadata
        """
        return {
            "session_directory": str(self.session_dir),
            "session_timestamp": self.session_timestamp,
            "title": self._session_title or "New Chat",
            "message_count": self.message_count,
            "last_message_timestamp": self.last_message_timestamp,
        }

    def estimate_tokens(self, text: str) -> int:
        """Estimate token count using tiktoken."""
        return len(self._encoding.encode(text))

    def get_total_context_tokens(self) -> int:
        """Calculate total tokens in current session context using actual LLM usage."""
        # Use actual token usage from cost tracking (more accurate than estimation)
        if hasattr(self.session_costs, 'total_usage') and self.session_costs.total_usage.total_tokens > 0:
            actual_tokens = self.session_costs.total_usage.total_tokens
            return actual_tokens
        
        # Fallback to message estimation if no usage data available
        total = 0
        for message in self.messages:
            if isinstance(message.get("content"), str):
                total += self.estimate_tokens(message["content"])

        if self.compressed_context:
            total += self.estimate_tokens(self.compressed_context)

        return total

    def should_compress_context(self) -> bool:
        """Check if context compression is needed (90% of context window)."""
        total_tokens = self.get_total_context_tokens()
        threshold = self.context_window * 0.9
        should_compress = total_tokens >= threshold
        
        return should_compress

    async def compress_context_if_needed(self) -> None:
        """Compress context when approaching token limits (reactive compression)."""
        if not self.should_compress_context():
            return

        # Import here to avoid circular imports
        from libagentic.agents import get_compression_agent
        from rich.progress import Progress, SpinnerColumn, TextColumn

        # Get compression metrics
        recent_preserve_count = 3
        messages_to_compress = (
            self.messages[:-recent_preserve_count] if len(self.messages) > recent_preserve_count else []
        )

        if not messages_to_compress:
            print("⚠️  No messages to compress")
            return

        # Simple transient indeterminate progress that disappears when done
        progress = Progress(
            SpinnerColumn(),
            TextColumn("🗜️  Compressing conversation..."),
            transient=True  # Progress disappears after completion
        )

        with progress:
            # Single indeterminate task
            task = progress.add_task("", total=None)  # Indeterminate progress
            
            # Format conversation for compression
            conversation_text = self._format_messages_for_compression(messages_to_compress)
            
            # Get compression agent and perform compression
            compression_agent = get_compression_agent()
            result = await compression_agent.run(f"Compress this conversation:\n\n{conversation_text}")
            
            # Store compressed context and remove compressed messages
            self.compressed_context = result.output.strip()
            self.messages = self.messages[-recent_preserve_count:]  # Keep only recent messages


        # Log compression event
        self._log_compression_event(len(messages_to_compress))

    def _format_messages_for_compression(self, messages: list[dict]) -> str:
        """Format messages into readable conversation for compression."""
        formatted = []
        for msg in messages:
            role = msg.get("type", "unknown")
            content = msg.get("content", "")

            if role == "user_message":
                formatted.append(f"USER: {content}")
            elif role == "assistant_response":
                formatted.append(f"ASSISTANT: {content}")
            elif role == "system_prompt":
                formatted.append(f"SYSTEM: {content}")

        return "\n\n".join(formatted)

    def _log_compression_event(self, compressed_message_count: int) -> None:
        """Log context compression as regular session message."""
        timestamp = datetime.now(UTC).isoformat()

        compression_data = {
            "timestamp": timestamp,
            "type": "context_compression",
            "content": f"Compressed {compressed_message_count} messages due to context window limit",
            "message_index": self.message_count,
            "metadata": {
                "compressed_messages": compressed_message_count,
                "remaining_messages": len(self.messages),
                "compressed_context_tokens": self.estimate_tokens(self.compressed_context)
                if self.compressed_context
                else 0,
            },
        }

        self.messages.append(compression_data)
        self.message_count += 1
        self.last_message_timestamp = timestamp
        self._log_message_to_history(compression_data)
        self._update_metadata()
